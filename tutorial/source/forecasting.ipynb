{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with Pyro: multivariate, hierarchical, and heavy tailed\n",
    "\n",
    "This tutorial introduces the [pyro.contrib.forecast](http://docs.pyro.ai/en/latest/contrib.forecast.html) module, a framework for forecasting with Pyro models.\n",
    "\n",
    "#### Summary\n",
    "- To create a forecasting model:\n",
    "  1. Create a subclass of the `ForecastingModel` class.\n",
    "  2. Implement the `.model(data, covariates)` method using standard Pyro syntax.\n",
    "  3. Sample ay time-local variables inside the `self.time_plate` context.\n",
    "  4. Finally call the `self.predict(noise_dist, prediction)` method.\n",
    "- To train a forecasting model, create a `Forecaster` object.\n",
    "- To forecast the future, draw samples from a `Forecaster` object conditioned on data and covariates.\n",
    "- To evaluate results, use the `backtest()` helper or the low-level loss functions.\n",
    "\n",
    "#### Table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.contrib.examples.bart import load_bart_od\n",
    "from pyro.contrib.forecast import ForecastingModel, Forecaster, backtest\n",
    "from pyro.infer.reparam import LocScaleReparam\n",
    "from pyro.ops.tensor_utils import periodic_cumsum, periodic_repeat, periodic_features\n",
    "from pyro.ops.stats import quantile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.rc = {'figure.facecolor': (1, 1, 1, 1)}\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "assert pyro.__version__.startswith('1.2.1')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(20200221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_bart_od()\n",
    "print(dataset.keys())\n",
    "print(dataset[\"counts\"].shape)\n",
    "print(\" \".join(dataset[\"stations\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Pyro's forecasting framework\n",
    "\n",
    "Pyro's forecasting framework consists of:\n",
    "- a [ForecastingModel]() base class, whose ``.model()`` method can be implemented for custom forecasting models,\n",
    "- a [Forecaster]() class that trains and forecasts using ``ForecastingModel``s, and\n",
    "- a [backtest]() helper to evaluate models on a number of metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ``ForecastingModel`` class\n",
    "\n",
    "Consider a simple univariate dataset, say weekly ridership aggregated over all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T, O, D = dataset[\"counts\"].shape\n",
    "data = dataset[\"counts\"][:T // (24 * 7) * 24 * 7].reshape(T // (24 * 7), -1).sum(-1).log()\n",
    "data = data.unsqueeze(-1)\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot(data)\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, len(data));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple log-linear regression model, with no trend or seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need some boilerplate to create a class and define a .model() method.\n",
    "class Model(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "\n",
    "        # The first part of the model is a probabilistic program to create a prediction.\n",
    "        # We use the zero_data as a template for the shape of the prediction.\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "        prediction = bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        # The prediction should have the same shape as zero_data (duration, obs_dim),\n",
    "        # but may have additional sample dimensions on the left.\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # The next part of the model creates a likelihood or noise distribution.\n",
    "        # Again we'll be Bayesian and write this as a probabilistic program with\n",
    "        # priors over parameters, and again we'll use zero_data as a noise template.\n",
    "        noise_scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Normal(zero_data, noise_scale)\n",
    "\n",
    "        # The final step is to call the .predict() method.\n",
    "        self.predict(noise_dist, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train this model by creating a [Forecaster]() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = 0\n",
    "T2 = data.size(-2)\n",
    "T1 = T2 - 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(T2)) / 365\n",
    "covariates = torch.stack([time], dim=-1)\n",
    "forecaster = Forecaster(Model(), data[:T1], covariates[:T1], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "print(samples.shape, p10.shape)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(T1, T2), data[T1:], 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(T1, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could add a yearly seasonal component simply by adding new covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(T2)) / 365\n",
    "covariates = torch.cat([time.unsqueeze(-1),\n",
    "                        periodic_features(T2, 365.25 / 7)], dim=-1)\n",
    "forecaster = Forecaster(Model(), data[:T1], covariates[:T1], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(T1, T2), data[T1:], 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(T1, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-local random variables: `self.time_plate`\n",
    "\n",
    "So far we've seen the ``ForecastingModel.model()`` method and ``self.predict()``. The last piece of forecasting-specific syntax is the ``self.time_plate`` context for time-local variables. To see how this works, consider changing our global linear trend model above to a local level model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "\n",
    "        # We'll sample a time-global scale parameter outside the time plate,\n",
    "        # then time-local iid noise inside the time plate.\n",
    "        drift_scale = pyro.sample(\"drift_scale\", dist.LogNormal(-20, 5).expand([1]).to_event(1))\n",
    "        with self.time_plate:\n",
    "            # We'll use a reparameterizer to improve variational fit.\n",
    "            with poutine.reparam(config={\"drift\": LocScaleReparam()}):\n",
    "                drift = pyro.sample(\"drift\", dist.Normal(zero_data, drift_scale).to_event(1))\n",
    "        motion = drift.cumsum(-2)  # A Brownian motion.\n",
    "        \n",
    "        prediction = motion + bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # The next part of the model creates a likelihood or noise distribution.\n",
    "        # Again we'll be Bayesian and write this as a probabilistic program with\n",
    "        # priors over parameters, and again we'll use zero_data as a noise template.\n",
    "        noise_scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Normal(zero_data, noise_scale)\n",
    "\n",
    "        # The final step is to call the .predict() method.\n",
    "        self.predict(noise_dist, prediction)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(T2)) / 365\n",
    "covariates = periodic_features(T2, 365.25 / 7)\n",
    "forecaster = Forecaster(Model(), data[:T1], covariates[:T1], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(T1, T2), data[T1:], 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(T1, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bivariate seasonal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full dataset has all station->station ridership counts for all of 50 train stations. In this simple example we will model only the aggretate counts to and from a single station, Embarcadero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = dataset[\"stations\"].index(\"EMBR\")\n",
    "arrivals = dataset[\"counts\"][:, :, i].sum(-1)\n",
    "departures = dataset[\"counts\"][:, i, :].sum(-1)\n",
    "data = torch.stack([arrivals, departures], dim=-1).log1p()\n",
    "covariates = torch.zeros(len(data), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        period = 24 * 7\n",
    "        duration, dim = zero_data.shape[-2:]\n",
    "        assert dim == 2  # Data is bivariate: (arrivals, departures).\n",
    "\n",
    "        # Sample global parameters.\n",
    "        noise_scale = pyro.sample(\"noise_scale\",\n",
    "                                  dist.LogNormal(torch.full((dim,), -3), 1).to_event(1))\n",
    "        assert noise_scale.shape[-1:] == (dim,)\n",
    "        trans_timescale = pyro.sample(\"trans_timescale\",\n",
    "                                      dist.LogNormal(torch.zeros(dim), 1).to_event(1))\n",
    "        assert trans_timescale.shape[-1:] == (dim,)\n",
    "\n",
    "        trans_loc = pyro.sample(\"trans_loc\", dist.Cauchy(0, 1 / period))\n",
    "        trans_loc = trans_loc.unsqueeze(-1).expand(trans_loc.shape + (dim,))\n",
    "        assert trans_loc.shape[-1:] == (dim,)\n",
    "\n",
    "        trans_scale = pyro.sample(\"trans_scale\",\n",
    "                                  dist.LogNormal(torch.zeros(dim), 0.1).to_event(1))\n",
    "        trans_corr = pyro.sample(\"trans_corr\",\n",
    "                                 dist.LKJCorrCholesky(dim, torch.ones(())))\n",
    "        trans_scale_tril = trans_scale.unsqueeze(-1) * trans_corr\n",
    "        assert trans_scale_tril.shape[-2:] == (dim, dim)\n",
    "\n",
    "        obs_scale = pyro.sample(\"obs_scale\",\n",
    "                                dist.LogNormal(torch.zeros(dim), 0.1).to_event(1))\n",
    "        obs_corr = pyro.sample(\"obs_corr\",\n",
    "                               dist.LKJCorrCholesky(dim, torch.ones(())))\n",
    "        obs_scale_tril = obs_scale.unsqueeze(-1) * obs_corr\n",
    "        assert obs_scale_tril.shape[-2:] == (dim, dim)\n",
    "\n",
    "        with pyro.plate(\"season_plate\", period,  dim=-1):\n",
    "            season_init = pyro.sample(\"season_init\",\n",
    "                                      dist.Normal(torch.zeros(dim), 1).to_event(1))\n",
    "            assert season_init.shape[-2:] == (period, dim)\n",
    "\n",
    "        # Sample independent noise at each time step.\n",
    "        with self.time_plate:\n",
    "            season_noise = pyro.sample(\"season_noise\",\n",
    "                                       dist.Normal(0, noise_scale).to_event(1))\n",
    "            assert season_noise.shape[-2:] == (duration, dim)\n",
    "\n",
    "        prediction = (periodic_repeat(season_init, duration, dim=-2) +\n",
    "                      periodic_cumsum(season_noise, period, dim=-2))\n",
    "        assert prediction.shape[-2:] == (duration, dim)\n",
    "\n",
    "        init_dist = dist.Normal(torch.zeros(dim), 100).to_event(1)\n",
    "        trans_mat = trans_timescale.neg().exp().diag_embed()\n",
    "        trans_dist = dist.MultivariateNormal(trans_loc, scale_tril=trans_scale_tril)\n",
    "        obs_mat = torch.eye(dim)\n",
    "        obs_dist = dist.MultivariateNormal(torch.zeros(dim), scale_tril=obs_scale_tril)\n",
    "        noise_model = dist.GaussianHMM(init_dist, trans_mat, trans_dist, obs_mat, obs_dist,\n",
    "                                       duration=duration)\n",
    "        assert noise_model.event_shape == (duration, dim)\n",
    "\n",
    "        self.predict(noise_model, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "t_train = 90 * 24\n",
    "forecaster = Forecaster(Model(), data[:t_train], covariates[:t_train],\n",
    "                        learning_rate=0.05,\n",
    "                        num_steps=501,\n",
    "                        log_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot(forecaster.losses)\n",
    "plt.ylabel(\"ELBO loss\")\n",
    "plt.xlabel(\"SVI step\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = 2 * 7 * 24\n",
    "samples = forecaster(data[:t_train], covariates[:t_train + t_test], num_samples=101)\n",
    "samples.clamp_(min=0);\n",
    "p05 = samples.kthvalue(5, dim=0).values\n",
    "p50 = samples.median(dim=0).values\n",
    "p95 = samples.kthvalue(95, dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(torch.arange(t_train - t_test // 2, t_train + t_test),\n",
    "         data[t_train - t_test // 2:t_train + t_test, 0], \"k-\")\n",
    "plt.plot(torch.arange(t_train - t_test // 2, t_train + t_test),\n",
    "         -data[t_train - t_test // 2:t_train + t_test, 1], \"k-\")\n",
    "plt.fill_between(torch.arange(t_train, t_train + t_test), p05[..., 0], p95[..., 0],\n",
    "                 color=\"pink\")\n",
    "plt.fill_between(torch.arange(t_train, t_train + t_test), -p05[..., 1], -p95[..., 1],\n",
    "                 color=\"pink\")\n",
    "plt.plot(torch.arange(t_train, t_train + t_test), p50[..., 0], \"r-\")\n",
    "plt.plot(torch.arange(t_train, t_train + t_test), -p50[..., 1], \"r-\")\n",
    "plt.ylabel(\"← departures  arrivals →\")\n",
    "plt.xlabel(\"hour after 2011-01-01\")\n",
    "plt.title(\"Forecast ridership at Embarcadero station\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical modeling using `pyro.plate`\n",
    "\n",
    "Hierarchical forecasting models use Pyro's standard mechanism for hierarchical modeling: the [pyro.plate](http://docs.pyro.ai/en/latest/primitives.html#pyro.plate) context manager. Let's start with a simple two level hierarchy, say modeling arrivals to each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        num_stations, duration, one = zero_data.shape\n",
    "\n",
    "        coefs = pyro.sample(\"coefs\",\n",
    "                            dist.Normal(0, 1).expand(covariates.shape[-1:]).to_evet(1))\n",
    "        global_seasonality = (coefs * covariates).sum(-1, keepdim=True)\n",
    "        with pyro.plate(\"station\", )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
